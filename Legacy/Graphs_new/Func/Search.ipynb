{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func.py — Functional-source model with plotting & utilities (full code)\n",
    "\n",
    "import os, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import eye, diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.interpolate import CubicSpline, PchipInterpolator, Akima1DInterpolator, interp1d\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.stats import linregress\n",
    "from numba import njit\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def _latex_sci(val, pow10_threshold=100.0):\n",
    "    \"\"\"Format val for LaTeX titles; switch to scientific when |val| ≥ threshold.\"\"\"\n",
    "    if val == 0:\n",
    "        return \"0\"\n",
    "    a = abs(val)\n",
    "    sign = \"-\" if val < 0 else \"\"\n",
    "    if a < pow10_threshold:\n",
    "        return f\"{val:g}\"\n",
    "    exp = int(np.floor(np.log10(a)))\n",
    "    mant = a / (10**exp)\n",
    "    if np.isclose(mant, 1.0, rtol=1e-10, atol=1e-12):\n",
    "        return rf\"{sign}10^{{{exp}}}\"\n",
    "    return rf\"{sign}{mant:.2g}\\times 10^{{{exp}}}\"\n",
    "\n",
    "def _file_sci(val, pow10_threshold=100.0):\n",
    "    \"\"\"Compact number for filenames: 1000 -> '1e3', 2500 -> '2.5e3', 10 -> '10'.\"\"\"\n",
    "    if val == 0:\n",
    "        return \"0\"\n",
    "    a = abs(val)\n",
    "    if a < pow10_threshold:\n",
    "        return f\"{int(val)}\" if float(val).is_integer() else f\"{val:g}\"\n",
    "    return f\"{val:.0e}\".replace(\"+0\",\"\").replace(\"+\",\"\").replace(\"e0\",\"e\")\n",
    "\n",
    "def _m0_two_digits(m0):\n",
    "    \"\"\"m0 in [0,1] to two digits: 0.0->'00', 0.5->'05', 1.0->'10'.\"\"\"\n",
    "    return f\"{int(round(m0*10)):02d}\"\n",
    "\n",
    "def _nearest_indices(t_vec, t_points):\n",
    "    return [int(np.argmin(np.abs(t_vec - t))) for t in t_points]\n",
    "\n",
    "# ----------------------------\n",
    "# Kernels\n",
    "# ----------------------------\n",
    "@njit\n",
    "def f_numba(N, rho, K):\n",
    "    # tumour growth: N_t = rho * N * (1 - N/K)\n",
    "    return rho * N * (1 - N / K)\n",
    "\n",
    "@njit\n",
    "def build_laplacian_diagonals_avg(m, D, dx):\n",
    "    \"\"\"\n",
    "    Variable-coefficient diffusion with edge-averaged M:\n",
    "      (D * M*(1-M) * u_x)_x  with homogeneous Neumann BCs.\n",
    "    Returns three diagonals (lower, center, upper) scaled by 1/dx^2.\n",
    "    \"\"\"\n",
    "    N = len(m)\n",
    "    lower = np.zeros(N)\n",
    "    center = np.zeros(N)\n",
    "    upper = np.zeros(N)\n",
    "\n",
    "    for i in range(1, N - 1):\n",
    "        ml = 0.5 * (m[i - 1] + m[i])\n",
    "        mr = 0.5 * (m[i] + m[i + 1])\n",
    "        Dl = max(1e-6, D * ml * (1 - ml))\n",
    "        Dr = max(1e-6, D * mr * (1 - mr))\n",
    "        lower[i] = Dl\n",
    "        upper[i] = Dr\n",
    "        center[i] = - (Dl + Dr)\n",
    "\n",
    "    # Neumann at x=0\n",
    "    mr = 0.5 * (m[0] + m[1])\n",
    "    Dr = max(1e-6, D * mr * (1 - mr))\n",
    "    center[0] = -2 * Dr\n",
    "    upper[0]  =  2 * Dr\n",
    "\n",
    "    # Neumann at x=L\n",
    "    ml = 0.5 * (m[-2] + m[-1])\n",
    "    Dl = max(1e-6, D * ml * (1 - ml))\n",
    "    center[-1] = -2 * Dl\n",
    "    lower[-1]  =  2 * Dl\n",
    "\n",
    "    invdx2 = 1.0 / dx**2\n",
    "    return invdx2 * lower, invdx2 * center, invdx2 * upper\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Main functional-source class\n",
    "# -------------------------------------------------\n",
    "class Dissertation_Func_1D:\n",
    "    \"\"\"\n",
    "    Functional source ECM dynamics:\n",
    "        m_t = alpha * (1 - m) - k * u * m\n",
    "    Tumour:\n",
    "        u_t = (D * m (1-m) u_x)_x + rho * u * (1 - u/K)\n",
    "    \"\"\"\n",
    "    def __init__(self, D=1.0, rho=1.0, K=1.0, k=1.0,\n",
    "                 alpha=1.0, n0=1.0, m0=0.5, Mmax=1.0, perc=0.2,\n",
    "                 L=1000.0, N=5001, T=1000.0, dt=0.1,\n",
    "                 scheme=\"AB2AM2\", init_type=\"step\", steepness=0.1,\n",
    "                 t_start=50.0, t_end=500.0, num_points=200):\n",
    "        # PDE/ODE params\n",
    "        self.D = D; self.rho = rho; self.K = K\n",
    "        self.k = k; self.alpha = alpha\n",
    "        self.n0 = n0; self.m0 = m0\n",
    "        self.Mmax = Mmax; self.perc = perc\n",
    "        self.steepness = steepness\n",
    "\n",
    "        # grid/time\n",
    "        self.L = L; self.N = N; self.dx = L / (N - 1)\n",
    "        self.x = np.linspace(0, L, N)\n",
    "        self.T = T; self.dt = dt; self.Nt = int(T / dt)\n",
    "        self.scheme = scheme.upper()\n",
    "        self.init_type = init_type\n",
    "\n",
    "        # storage\n",
    "        self.times = np.linspace(0, T, self.Nt)\n",
    "        self.N_arr = np.zeros((self.Nt, self.N))\n",
    "        self.M_arr = np.zeros((self.Nt, self.N))\n",
    "        self.wave_speed = None  # filled later\n",
    "\n",
    "        # front-tracking window\n",
    "        self.t_start = t_start\n",
    "        self.t_end = t_end\n",
    "        self.num_points = num_points\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Solver\n",
    "    # ---------------------------------------\n",
    "    def initial_condition(self):\n",
    "        if self.init_type == \"step\":\n",
    "            N0 = self.n0 * np.where(self.x < self.perc * self.L, 0.7, 0.0)\n",
    "        elif self.init_type == \"tanh\":\n",
    "            N0 = self.n0 * 0.5 * (1 - np.tanh(self.steepness * (self.x - self.perc * self.L)))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown initial condition.\")\n",
    "        M0 = self.m0 * self.Mmax * np.ones_like(self.x)\n",
    "        return N0, M0\n",
    "\n",
    "    def update_laplacian(self, M):\n",
    "        lower, center, upper = build_laplacian_diagonals_avg(M, self.D, self.dx)\n",
    "        return diags([lower[1:], center, upper[:-1]], [-1, 0, 1], format=\"csr\")\n",
    "\n",
    "    def solve(self):\n",
    "        # initial data\n",
    "        N_prev, M_prev = self.initial_condition()\n",
    "        f_prev = f_numba(N_prev, self.rho, self.K)\n",
    "        L_prev = self.update_laplacian(M_prev)\n",
    "\n",
    "        # first step for u (implicit Euler in diffusion)\n",
    "        A0 = (eye(self.N) - self.dt * L_prev)\n",
    "        N_curr = spsolve(A0.tocsc(), N_prev + self.dt * f_prev)\n",
    "\n",
    "        # first step for m (implicit Euler with u^{1})\n",
    "        denom = 1.0 + self.dt * (self.alpha + self.k * np.maximum(N_curr, 0.0))\n",
    "        M_curr = (M_prev + self.alpha * self.dt) / denom\n",
    "        np.clip(M_curr, 0.0, self.Mmax, out=M_curr)\n",
    "\n",
    "        # store first two frames\n",
    "        self.N_arr[0], self.M_arr[0] = N_prev, M_prev\n",
    "        self.N_arr[1], self.M_arr[1] = N_curr, M_curr\n",
    "\n",
    "        # main loop\n",
    "        for i in range(2, self.Nt):\n",
    "            # operator with current m\n",
    "            L_curr = self.update_laplacian(M_curr)\n",
    "            f_curr = f_numba(N_curr, self.rho, self.K)\n",
    "\n",
    "            # AB2–AM2 for u\n",
    "            rhs = (eye(self.N) + 0.5 * self.dt * L_prev) @ N_curr \\\n",
    "                  + self.dt * (1.5 * f_curr - 0.5 * f_prev)\n",
    "            A = (eye(self.N) - 0.5 * self.dt * L_curr)\n",
    "            N_next = spsolve(A.tocsc(), rhs)\n",
    "\n",
    "            # Neumann ends for u by copying neighbors\n",
    "            N_next[0], N_next[-1] = N_next[1], N_next[-2]\n",
    "\n",
    "            # implicit Euler for m using u^{n+1}\n",
    "            denom = 1.0 + self.dt * (self.alpha + self.k * np.maximum(N_next, 0.0))\n",
    "            M_next = (M_curr + self.alpha * self.dt) / denom\n",
    "            np.clip(M_next, 0.0, self.Mmax, out=M_next)\n",
    "\n",
    "            # store & roll\n",
    "            self.N_arr[i] = N_next\n",
    "            self.M_arr[i] = M_next\n",
    "            N_prev, N_curr = N_curr, N_next\n",
    "            M_prev, M_curr = M_curr, M_next\n",
    "            f_prev = f_curr\n",
    "            L_prev = L_curr\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Front tracking & speed estimation\n",
    "    # ---------------------------------------\n",
    "    def _get_spline(self, method, x, y):\n",
    "        m = method.lower()\n",
    "        if m == 'cubic':  return CubicSpline(x, y)\n",
    "        if m == 'pchip':  return PchipInterpolator(x, y)\n",
    "        if m == 'akima':  return Akima1DInterpolator(x, y)\n",
    "        if m == 'linear': return interp1d(x, y, kind='linear', fill_value=\"extrapolate\")\n",
    "        raise ValueError(f\"Unsupported spline_type: {method}\")\n",
    "\n",
    "    def track_wavefront_local_interpolation(self, threshold=0.5, band=(0.1, 0.9),\n",
    "                                            spline_type='cubic', target='N'):\n",
    "        x = self.x\n",
    "        t_vec = self.times\n",
    "        u_arr = self.N_arr if target.lower() == 'n' else self.M_arr\n",
    "        t_list = np.linspace(self.t_start, self.t_end, self.num_points)\n",
    "        x_fronts, t_fronts = [], []\n",
    "\n",
    "        for t_target in t_list:\n",
    "            idx = int(np.argmin(np.abs(t_vec - t_target)))\n",
    "            u = u_arr[idx]\n",
    "            mask = (u > band[0]) & (u < band[1])\n",
    "            if np.sum(mask) < 5:\n",
    "                continue\n",
    "            x_local, u_local = x[mask], u[mask]\n",
    "            sidx = np.argsort(x_local)\n",
    "            x_local, u_local = x_local[sidx], u_local[sidx]\n",
    "            spline = self._get_spline(spline_type, x_local, u_local)\n",
    "\n",
    "            # find first threshold crossing in the band\n",
    "            sign_change = np.where(\n",
    "                np.sign(u_local[:-1] - threshold) != np.sign(u_local[1:] - threshold)\n",
    "            )[0]\n",
    "            if len(sign_change) == 0:\n",
    "                continue\n",
    "            i = int(sign_change[0])\n",
    "            xl, xr = x_local[i], x_local[i + 1]\n",
    "\n",
    "            try:\n",
    "                sol = root_scalar(lambda xv: spline(xv) - threshold, bracket=[xl, xr])\n",
    "                if sol.converged:\n",
    "                    x_fronts.append(sol.root)\n",
    "                    t_fronts.append(t_target)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        return np.array(t_fronts), np.array(x_fronts)\n",
    "\n",
    "    def estimate_wave_speed(self, threshold=0.5, band=(0.1, 0.9),\n",
    "                            spline_type='cubic', plot=True, target='N'):\n",
    "        t_fronts, x_fronts = self.track_wavefront_local_interpolation(\n",
    "            threshold=threshold, band=band, spline_type=spline_type, target=target\n",
    "        )\n",
    "        if len(t_fronts) < 2:\n",
    "            print(\"❌ Not enough valid front points.\")\n",
    "            return None, None, None\n",
    "\n",
    "        slope, intercept, r_value, _, _ = linregress(t_fronts, x_fronts)\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(t_fronts, x_fronts, 'o', label='Front')\n",
    "            plt.plot(t_fronts, slope * t_fronts + intercept, 'k--',\n",
    "                     label=f'Slope = {slope:.3f},  $R^2$ = {r_value**2:.4f}')\n",
    "            plt.xlabel(\"Time t\")\n",
    "            plt.ylabel(\"Wavefront x(t)\")\n",
    "            plt.title(\"Wave speed via linear fit\")\n",
    "            plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        return slope, intercept, r_value**2\n",
    "\n",
    "    def plot_speed_curve(self, threshold=0.5, band=(0.1, 0.9), spline_type='cubic', target='N'):\n",
    "        \"\"\"\n",
    "        Show x_front vs t with best-fit line and annotate R^2.\n",
    "        Returns (speed, intercept, R2).\n",
    "        \"\"\"\n",
    "        t_fronts, x_fronts = self.track_wavefront_local_interpolation(\n",
    "            threshold=threshold, band=band, spline_type=spline_type, target=target\n",
    "        )\n",
    "        if len(t_fronts) < 2:\n",
    "            print(\"❌ Not enough valid front points.\")\n",
    "            return None, None, None\n",
    "\n",
    "        slope, intercept, r_value, _, _ = linregress(t_fronts, x_fronts)\n",
    "        r2 = r_value**2\n",
    "\n",
    "        plt.figure(figsize=(8, 4.6))\n",
    "        plt.plot(t_fronts, x_fronts, 'o', label='Front samples')\n",
    "        plt.plot(t_fronts, slope * t_fronts + intercept, 'k--',\n",
    "                 label=f'$c$={slope:.4f}, $R^2$={r2:.4f}')\n",
    "        plt.xlabel(\"Time $t$\")\n",
    "        plt.ylabel(\"Front position $x(t)$\")\n",
    "        plt.title(\"Wave speed estimation\")\n",
    "        plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        self.wave_speed = slope\n",
    "        return slope, intercept, r2\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Publication-ready snapshot plot(s)\n",
    "    # ---------------------------------------\n",
    "    def plot_u_m_with_custom_style(self, \n",
    "                                   t_points=[0, 100, 200, 300],\n",
    "                                   target=\"both\",          # \"u\", \"m\", or \"both\"\n",
    "                                   yticks_mode=\"basic\", \n",
    "                                   show_arrows=True,\n",
    "                                   show_speed_text=True,\n",
    "                                   print_speed=False,\n",
    "                                   ceil_speed=False,     \n",
    "                                   arrow_len=None, arrow_lw=2.5,\n",
    "                                   arrow_x_frac=0.7,     \n",
    "                                   y_red=0.8,            \n",
    "                                   y_blue=0.25,          \n",
    "                                   head_length=1.5, head_width=0.65,\n",
    "                                   save=False, folder=\"Plots_Func\", filename=None):\n",
    "        \"\"\"\n",
    "        Plot snapshots of u, m, or both (depending on target).\n",
    "        \"\"\"\n",
    "        x, N_arr, M_arr, t_vec = self.x, self.N_arr, self.M_arr, self.times\n",
    "\n",
    "        # Map requested times -> nearest indices\n",
    "        t_indices = [int(np.argmin(np.abs(t_vec - t))) for t in t_points]\n",
    "\n",
    "        # Optionally compute wave speed (for annotation)\n",
    "        if (show_speed_text or print_speed) and getattr(self, \"wave_speed\", None) is None:\n",
    "            self.wave_speed, _, _ = self.estimate_wave_speed(\n",
    "                plot=False, target='N', threshold=0.5, band=(0.1, 0.9), spline_type='cubic'\n",
    "            )\n",
    "        if print_speed and (self.wave_speed is not None):\n",
    "            print(f\"[func plot] Estimated wave speed c = {self.wave_speed:.6g}\")\n",
    "\n",
    "        # Speed string\n",
    "        c_str = \"—\"\n",
    "        if self.wave_speed is not None:\n",
    "            if ceil_speed == \"down\":\n",
    "                c_str = f\"{math.floor(self.wave_speed * 100) / 100:.2f}\"\n",
    "            elif ceil_speed == \"up\":\n",
    "                c_str = f\"{math.ceil(self.wave_speed * 100) / 100:.2f}\"\n",
    "            else:\n",
    "                c_str = f\"{self.wave_speed:.3g}\"\n",
    "\n",
    "        # Arrow geometry\n",
    "        if arrow_len is None:\n",
    "            arrow_len = 0.15 * self.L\n",
    "        arrow_x_start = np.clip(arrow_x_frac * self.L, 0.0, self.L)\n",
    "        arrow_x_end   = np.clip(arrow_x_start + arrow_len, 0.0, self.L)\n",
    "        if arrow_x_end <= arrow_x_start:\n",
    "            arrow_x_start = np.clip(self.L - arrow_len, 0.0, self.L)\n",
    "            arrow_x_end   = self.L\n",
    "\n",
    "        # Figure\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Plot series\n",
    "        targ = target.lower()\n",
    "        for t, tidx in zip(t_points, t_indices):\n",
    "            ls = '--' if np.isclose(t, 0.0) else '-'\n",
    "            if targ in (\"u\", \"both\"):\n",
    "                ax.plot(x, N_arr[tidx], color='red',  linestyle=ls, label=rf\"$u(x,{int(t)})$\")\n",
    "            if targ in (\"m\", \"both\"):\n",
    "                ax.plot(x, M_arr[tidx], color='blue', linestyle=ls, label=rf\"$m(x,{int(t)})$\")\n",
    "\n",
    "        # Direction arrows (only if both)\n",
    "        if show_arrows and targ == \"both\":\n",
    "            arrow_style_red  = dict(arrowstyle=f'->,head_length={head_length},head_width={head_width}',\n",
    "                                    color='red',  lw=arrow_lw)\n",
    "            arrow_style_blue = dict(arrowstyle=f'->,head_length={head_length},head_width={head_width}',\n",
    "                                    color='blue', lw=arrow_lw)\n",
    "            ax.annotate('', xy=(arrow_x_end, y_red),  xytext=(arrow_x_start, y_red),  arrowprops=arrow_style_red)\n",
    "            ax.annotate('', xy=(arrow_x_end, y_blue), xytext=(arrow_x_start, y_blue), arrowprops=arrow_style_blue)\n",
    "\n",
    "        # Corner text\n",
    "        x_text = x[0] + 0.02 * self.L\n",
    "        ax.text(x_text, 0.92, rf\"$\\overline{{m}} = {self.m0}$\", fontsize=18, ha='left')\n",
    "        if show_speed_text and (self.wave_speed is not None):\n",
    "            ax.text(x_text, 0.82, rf\"$c = {c_str}$\", fontsize=18, ha='left')\n",
    "\n",
    "        # Axes + title\n",
    "        ax.set_xlabel(r\"$x$\", fontsize=18)\n",
    "        if targ == \"u\":\n",
    "            ax.set_ylabel(r\"$u(x,t)$\", fontsize=18)\n",
    "        elif targ == \"m\":\n",
    "            ax.set_ylabel(r\"$m(x,t)$\", fontsize=18)\n",
    "        else:\n",
    "            ax.set_ylabel(r\"$u(x,t),\\, m(x,t)$\", fontsize=18)\n",
    "        ax.set_xlim([0, self.L])\n",
    "\n",
    "        mode = str(yticks_mode).lower()\n",
    "        if mode == \"basic\":\n",
    "            ax.set_ylim([0, 1.05]); ax.set_yticks([0.0, 0.5, 1.0])\n",
    "        elif mode == \"split\":\n",
    "            ax.set_ylim([0, 1.05]); ax.set_yticks(np.arange(0.0, 1.01, 0.2))\n",
    "        elif mode == \"splitplus\":\n",
    "            ax.set_ylim([0, 1.25]); ax.set_yticks(np.arange(0.0, 1.21, 0.2))\n",
    "        else:\n",
    "            ax.set_ylim([0, 1.05]); ax.set_yticks([0.0, 0.5, 1.0])\n",
    "\n",
    "        ax.tick_params(axis='y', labelsize=16)\n",
    "        ax.tick_params(axis='x', labelsize=16)\n",
    "        lam_str = _latex_sci(self.k, pow10_threshold=100.0)\n",
    "        ax.set_title(rf\"$\\lambda = {lam_str}$\", fontsize=20)\n",
    "        ax.grid(False)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Save or show\n",
    "        if save:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            m0_str = _m0_two_digits(self.m0)\n",
    "            lam_file = _file_sci(self.k, 100.0)\n",
    "            fname = filename or f\"func_{m0_str}_lam{lam_file}_{targ}.png\"\n",
    "            outpath = os.path.join(folder, fname)\n",
    "            fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "            print(f\"[func plot] Figure saved to {outpath}\")\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Imports ====\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# -------------------------\n",
    "# Save / path helpers\n",
    "# -------------------------\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _atomic_write_json(path: Path, obj):\n",
    "    tmp = path.with_suffix(\".tmp\")\n",
    "    with open(tmp, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def _save_summary(run_dir: Path, meta: dict):\n",
    "    with open(run_dir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "def _save_fronts(run_dir: Path, t_fronts, x_fronts, name=None):\n",
    "    fname = \"fronts.npz\" if not name else f\"fronts_{name}.npz\"\n",
    "    np.savez_compressed(run_dir / fname,\n",
    "                        t_fronts=np.asarray(t_fronts),\n",
    "                        x_fronts=np.asarray(x_fronts))\n",
    "\n",
    "def _save_snapshots_every_stride(run_dir: Path, model, stride=150):\n",
    "    \"\"\"\n",
    "    Save EVERY `stride`-th snapshot (plus the last one), with U and M kept separate.\n",
    "    \"\"\"\n",
    "    idx = np.unique(np.concatenate([\n",
    "        np.arange(0, model.Nt, stride),\n",
    "        np.array([model.Nt - 1])\n",
    "    ]))\n",
    "    np.savez_compressed(\n",
    "        run_dir / \"snapshots.npz\",\n",
    "        x=model.x,\n",
    "        times=model.times[idx],\n",
    "        N_arr=model.N_arr[idx, :],   # tumour u(x,t)\n",
    "        M_arr=model.M_arr[idx, :]    # ECM   m(x,t)\n",
    "    )\n",
    "\n",
    "def _fmt_val(v):\n",
    "    # compact label in folder names: keeps ints clean (e.g., 10 not 10.0)\n",
    "    if isinstance(v, (int, np.integer)) or (isinstance(v, float) and v.is_integer()):\n",
    "        return f\"{int(v)}\"\n",
    "    s = f\"{v}\"\n",
    "    return s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "\n",
    "# -------------------------\n",
    "# Single-run worker\n",
    "# -------------------------\n",
    "def run_one(lam, alpha, m0,\n",
    "            base_dir=\"speeds_func\",\n",
    "            model_kwargs=None,\n",
    "            overwrite=False,\n",
    "            snapshot_stride=150):\n",
    "    \"\"\"\n",
    "    Builds, solves, measures, and saves one (λ, α, m0) run.\n",
    "\n",
    "    Skips a run if base_dir/lambda_*/alpha_*/m0_*/summary.json exists and overwrite=False.\n",
    "    Saves:\n",
    "      - summary.json (metadata + c, R^2)\n",
    "      - fronts.npz    (t_fronts, x_fronts for N at threshold 0.5)\n",
    "      - snapshots.npz (x, times[idx], N_arr[idx,:], M_arr[idx,:]) with idx every `snapshot_stride`\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    try:\n",
    "        # Shallow copy of shared kwargs\n",
    "        local_kwargs = dict(model_kwargs)\n",
    "\n",
    "        # Optional per-λ overrides (example: finer time-step for very large λ, if you want)\n",
    "        # if float(lam) >= 1e3:\n",
    "        #     local_kwargs.update(dict(dt=0.01))\n",
    "\n",
    "        base = Path(base_dir)\n",
    "        lam_dir = base / f\"lambda_{_fmt_val(lam)}\"\n",
    "        alpha_dir = lam_dir / f\"alpha_{_fmt_val(alpha)}\"\n",
    "        run_dir = alpha_dir / f\"m0_{_fmt_val(m0)}\"\n",
    "        _ensure_dir(run_dir)\n",
    "\n",
    "        # Skip if already done (unless overwrite=True)\n",
    "        if not overwrite and (run_dir / \"summary.json\").exists():\n",
    "            return (\"skipped\", lam, alpha, m0)\n",
    "\n",
    "        # Avoid thread over-subscription (OpenMP/BLAS)\n",
    "        os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "        # Build and solve\n",
    "        model = Dissertation_Func_1D(k=lam, alpha=alpha, m0=m0, **local_kwargs)\n",
    "        model.solve()\n",
    "\n",
    "        # Speed on u (N)\n",
    "        c, b, r2 = model.estimate_wave_speed(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic',\n",
    "            plot=False, target='N'\n",
    "        )\n",
    "        if (c is None) or (isinstance(c, float) and np.isnan(c)):\n",
    "            raise ValueError(\"Wave speed could not be calculated.\")\n",
    "        model.wave_speed = c\n",
    "\n",
    "        # Front points (N)\n",
    "        t_fronts, x_fronts = model.track_wavefront_local_interpolation(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic', target='N'\n",
    "        )\n",
    "\n",
    "        # Save artifacts\n",
    "        _save_summary(run_dir, dict(\n",
    "            lambda_val=float(lam),\n",
    "            alpha=float(alpha),\n",
    "            m0=float(m0),\n",
    "            wave_speed=float(c),\n",
    "            r2=(float(r2) if r2 is not None else None),\n",
    "            # useful context\n",
    "            dt=model.dt, T=model.T, L=model.L, N=model.N,\n",
    "            init_type=model.init_type,\n",
    "            steepness=getattr(model, \"steepness\", None),\n",
    "            perc=getattr(model, \"perc\", None),\n",
    "            t_start=model.t_start, t_end=model.t_end,\n",
    "            num_points=getattr(model, \"num_points\", None),\n",
    "            saved_stride=int(snapshot_stride)\n",
    "        ))\n",
    "        _save_fronts(run_dir, t_fronts, x_fronts, name=\"N\")\n",
    "        _save_snapshots_every_stride(run_dir, model, stride=snapshot_stride)\n",
    "\n",
    "        return (\"done\", lam, alpha, m0, float(c), (float(r2) if r2 is not None else None))\n",
    "\n",
    "    except Exception as e:\n",
    "        return (\"failed\", lam, alpha, m0, str(e))\n",
    "\n",
    "# -------------------------\n",
    "# Parallel grid runner\n",
    "# -------------------------\n",
    "def run_grid(lambda_vals, alpha_vals, m0_vals,\n",
    "             base_dir=\"speeds_func\",\n",
    "             model_kwargs=None,\n",
    "             overwrite=False,\n",
    "             snapshot_stride=150,\n",
    "             n_jobs=-1, verbose=10):\n",
    "    \"\"\"\n",
    "    Launch all (λ, α, m0) runs in parallel and log failures & low-R² cases.\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    tasks = [(lam, alpha, m0) for lam in lambda_vals for alpha in alpha_vals for m0 in m0_vals]\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=verbose, backend=\"loky\")(\n",
    "        delayed(run_one)(\n",
    "            lam, alpha, m0,\n",
    "            base_dir=base_dir,\n",
    "            model_kwargs=model_kwargs,\n",
    "            overwrite=overwrite,\n",
    "            snapshot_stride=snapshot_stride\n",
    "        ) for lam, alpha, m0 in tasks\n",
    "    )\n",
    "\n",
    "    done, skipped, failed, low_r2 = [], [], [], []\n",
    "    for r in results:\n",
    "        tag = r[0]\n",
    "        if tag == \"done\":\n",
    "            _, lam, alpha_eff, m0_eff, c, r2 = r\n",
    "            done.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"c\": c, \"r2\": r2})\n",
    "            if (r2 is None) or (isinstance(r2, float) and (np.isnan(r2) or r2 < .999)):\n",
    "                low_r2.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"c\": c, \"r2\": r2})\n",
    "        elif tag == \"skipped\":\n",
    "            _, lam, alpha_eff, m0_eff = r\n",
    "            skipped.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff})\n",
    "        elif tag == \"failed\":\n",
    "            _, lam, alpha_orig, m0_orig, msg = r\n",
    "            failed.append({\"lambda\": lam, \"alpha\": alpha_orig, \"m0\": m0_orig, \"error\": msg})\n",
    "\n",
    "    base = Path(base_dir)\n",
    "    _ensure_dir(base)\n",
    "    _atomic_write_json(base / \"failed_runs.json\", failed)\n",
    "    _atomic_write_json(base / \"low_r2_runs.json\", low_r2)\n",
    "\n",
    "    print(f\"✅ Done: {len(done)}, Skipped: {len(skipped)}, Failed: {len(failed)}, Low-R²: {len(low_r2)}\")\n",
    "    if failed:\n",
    "        print(\"❌ Failed runs (sample):\")\n",
    "        for item in failed[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | error: {item['error']}\")\n",
    "    if low_r2:\n",
    "        print(\"⚠️  Low-R² runs (R² < 0.999):\")\n",
    "        for item in low_r2[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | c={item['c']} | r2={item['r2']}\")\n",
    "\n",
    "    return {\"done\": done, \"skipped\": skipped, \"failed\": failed, \"low_r2\": low_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed: 33.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed: 38.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed: 42.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 60.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed: 65.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 70.7min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed: 77.2min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed: 83.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed: 90.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed: 96.0min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed: 103.9min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed: 110.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 117.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed: 125.5min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 133.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 142.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed: 150.8min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed: 159.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed: 168.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed: 178.0min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed: 187.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed: 197.9min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed: 207.6min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed: 218.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed: 230.0min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed: 241.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Not enough valid front points.\n",
      "❌ Not enough valid front points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed: 252.5min\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed: 263.7min\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed: 275.6min\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed: 287.9min\n",
      "[Parallel(n_jobs=8)]: Done 997 tasks      | elapsed: 300.1min\n",
      "[Parallel(n_jobs=8)]: Done 1042 tasks      | elapsed: 312.3min\n",
      "[Parallel(n_jobs=8)]: Done 1089 tasks      | elapsed: 325.7min\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed: 339.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: 1150, Skipped: 0, Failed: 33, Low-R²: 97\n",
      "❌ Failed runs (sample):\n",
      "  λ=0.001, α=100000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.001, α=1000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.001, α=10000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.001, α=100000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.01, α=100000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.01, α=1000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.01, α=10000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.01, α=100000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.1, α=100000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.1, α=1000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.1, α=10000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.1, α=100000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.5, α=100000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.5, α=1000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.5, α=10000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=0.5, α=100000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=1, α=100000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=1, α=1000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=1, α=10000000, m0=0 | error: Wave speed could not be calculated.\n",
      "  λ=1, α=100000000, m0=0 | error: Wave speed could not be calculated.\n",
      "⚠️  Low-R² runs (R² < 0.999):\n",
      "  λ=0.001, α=0.001, m0=0 | c=0.6640193500345519 | r2=0.9986926353043327\n",
      "  λ=0.001, α=0.001, m0=0.01 | c=0.6777165058936973 | r2=0.9989748773107296\n",
      "  λ=0.001, α=0.1, m0=0 | c=0.1825422738218574 | r2=0.9939823199012505\n",
      "  λ=0.001, α=0.1, m0=0.01 | c=0.18254901365038861 | r2=0.9939817531622139\n",
      "  λ=0.001, α=0.1, m0=0.05 | c=0.18245838266681294 | r2=0.9939920615285572\n",
      "  λ=0.001, α=0.1, m0=0.1 | c=0.1820808563510841 | r2=0.9940340471360012\n",
      "  λ=0.001, α=0.1, m0=0.2 | c=0.180424092727537 | r2=0.9942266700510298\n",
      "  λ=0.001, α=0.1, m0=0.3 | c=0.17762218665941246 | r2=0.9946744215865934\n",
      "  λ=0.001, α=0.1, m0=0.4 | c=0.17429039383805775 | r2=0.9957977145424453\n",
      "  λ=0.01, α=0.001, m0=0 | c=0.6640119156382028 | r2=0.9986925050736413\n",
      "  λ=0.01, α=0.001, m0=0.01 | c=0.6777088708876579 | r2=0.9989748671840731\n",
      "  λ=0.01, α=0.1, m0=0 | c=0.18264704470492743 | r2=0.9939723908021825\n",
      "  λ=0.01, α=0.1, m0=0.01 | c=0.18265378563857973 | r2=0.9939718258620758\n",
      "  λ=0.01, α=0.1, m0=0.05 | c=0.1825631199077445 | r2=0.9939821143570267\n",
      "  λ=0.01, α=0.1, m0=0.1 | c=0.1821854532100542 | r2=0.9940240122392252\n",
      "  λ=0.01, α=0.1, m0=0.2 | c=0.1805279389589476 | r2=0.9942161795224941\n",
      "  λ=0.01, α=0.1, m0=0.3 | c=0.17772291420308897 | r2=0.9946622451252844\n",
      "  λ=0.01, α=0.1, m0=0.4 | c=0.1743785768284458 | r2=0.9957805409665484\n",
      "  λ=0.1, α=0.001, m0=0 | c=0.6639379143538375 | r2=0.9986912320982579\n",
      "  λ=0.1, α=0.001, m0=0.01 | c=0.6776331974849817 | r2=0.9989747210232712\n",
      "\n",
      "=== Summary of Problematic Runs ===\n",
      "FAIL -> λ=0.001, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.001, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.001, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.001, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.01, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.01, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.01, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.01, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.1, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.1, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.1, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.1, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.5, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.5, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.5, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=0.5, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=1, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=1, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=1, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=1, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=5, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=5, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=5, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=5, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=10, α=100000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=10, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=10, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=10, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=100, α=1000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=100, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=100, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=1000, α=10000000, m0=0 | Wave speed could not be calculated.\n",
      "FAIL -> λ=1000, α=100000000, m0=0 | Wave speed could not be calculated.\n",
      "LOW R² -> λ=0.001, α=0.001, m0=0 | r2=0.9986926353043327\n",
      "LOW R² -> λ=0.001, α=0.001, m0=0.01 | r2=0.9989748773107296\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0 | r2=0.9939823199012505\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.01 | r2=0.9939817531622139\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.05 | r2=0.9939920615285572\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.1 | r2=0.9940340471360012\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.2 | r2=0.9942266700510298\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.3 | r2=0.9946744215865934\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.4 | r2=0.9957977145424453\n",
      "LOW R² -> λ=0.01, α=0.001, m0=0 | r2=0.9986925050736413\n",
      "LOW R² -> λ=0.01, α=0.001, m0=0.01 | r2=0.9989748671840731\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0 | r2=0.9939723908021825\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0.01 | r2=0.9939718258620758\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0.05 | r2=0.9939821143570267\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0.1 | r2=0.9940240122392252\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0.2 | r2=0.9942161795224941\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0.3 | r2=0.9946622451252844\n",
      "LOW R² -> λ=0.01, α=0.1, m0=0.4 | r2=0.9957805409665484\n",
      "LOW R² -> λ=0.1, α=0.001, m0=0 | r2=0.9986912320982579\n",
      "LOW R² -> λ=0.1, α=0.001, m0=0.01 | r2=0.9989747210232712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1183 out of 1183 | elapsed: 351.1min finished\n"
     ]
    }
   ],
   "source": [
    "# ==== Imports ====\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# -------------------------\n",
    "# Save / path helpers\n",
    "# -------------------------\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _atomic_write_json(path: Path, obj):\n",
    "    tmp = path.with_suffix(\".tmp\")\n",
    "    with open(tmp, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def _save_summary(run_dir: Path, meta: dict):\n",
    "    with open(run_dir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "def _save_fronts(run_dir: Path, t_fronts, x_fronts, name=None):\n",
    "    fname = \"fronts.npz\" if not name else f\"fronts_{name}.npz\"\n",
    "    np.savez_compressed(run_dir / fname,\n",
    "                        t_fronts=np.asarray(t_fronts),\n",
    "                        x_fronts=np.asarray(x_fronts))\n",
    "\n",
    "def _save_snapshots_every_stride(run_dir: Path, model, stride=150):\n",
    "    \"\"\"\n",
    "    Save EVERY `stride`-th snapshot (plus the last one), with U and M kept separate.\n",
    "    \"\"\"\n",
    "    idx = np.unique(np.concatenate([\n",
    "        np.arange(0, model.Nt, stride),\n",
    "        np.array([model.Nt - 1])\n",
    "    ]))\n",
    "    np.savez_compressed(\n",
    "        run_dir / \"snapshots.npz\",\n",
    "        x=model.x,\n",
    "        times=model.times[idx],\n",
    "        N_arr=model.N_arr[idx, :],   # tumour u(x,t)\n",
    "        M_arr=model.M_arr[idx, :]    # ECM   m(x,t)\n",
    "    )\n",
    "\n",
    "def _fmt_val(v):\n",
    "    # compact label in folder names: keeps ints clean (e.g., 10 not 10.0)\n",
    "    if isinstance(v, (int, np.integer)) or (isinstance(v, float) and v.is_integer()):\n",
    "        return f\"{int(v)}\"\n",
    "    s = f\"{v}\"\n",
    "    return s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "\n",
    "# -------------------------\n",
    "# Single-run worker\n",
    "# -------------------------\n",
    "def run_one(lam, alpha, m0,\n",
    "            base_dir=\"speeds_func\",\n",
    "            model_kwargs=None,\n",
    "            overwrite=False,\n",
    "            snapshot_stride=150):\n",
    "    \"\"\"\n",
    "    Builds, solves, measures, and saves one (λ, α, m0) run.\n",
    "\n",
    "    Skips a run if base_dir/lambda_*/alpha_*/m0_*/summary.json exists and overwrite=False.\n",
    "    Saves:\n",
    "      - summary.json (metadata + c, R^2)\n",
    "      - fronts.npz    (t_fronts, x_fronts for N at threshold 0.5)\n",
    "      - snapshots.npz (x, times[idx], N_arr[idx,:], M_arr[idx,:]) with idx every `snapshot_stride`\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    try:\n",
    "        # Shallow copy of shared kwargs\n",
    "        local_kwargs = dict(model_kwargs)\n",
    "\n",
    "        # Optional per-λ overrides (example: finer time-step for very large λ, if you want)\n",
    "        # if float(lam) >= 1e3:\n",
    "        #     local_kwargs.update(dict(dt=0.01))\n",
    "\n",
    "        base = Path(base_dir)\n",
    "        lam_dir = base / f\"lambda_{_fmt_val(lam)}\"\n",
    "        alpha_dir = lam_dir / f\"alpha_{_fmt_val(alpha)}\"\n",
    "        run_dir = alpha_dir / f\"m0_{_fmt_val(m0)}\"\n",
    "        _ensure_dir(run_dir)\n",
    "\n",
    "        # Skip if already done (unless overwrite=True)\n",
    "        if not overwrite and (run_dir / \"summary.json\").exists():\n",
    "            return (\"skipped\", lam, alpha, m0)\n",
    "\n",
    "        # Avoid thread over-subscription (OpenMP/BLAS)\n",
    "        os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "        # Build and solve\n",
    "        model = Dissertation_Func_1D(k=lam, alpha=alpha, m0=m0, **local_kwargs)\n",
    "        model.solve()\n",
    "\n",
    "        # Speed on u (N)\n",
    "        c, b, r2 = model.estimate_wave_speed(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic',\n",
    "            plot=False, target='N'\n",
    "        )\n",
    "        if (c is None) or (isinstance(c, float) and np.isnan(c)):\n",
    "            raise ValueError(\"Wave speed could not be calculated.\")\n",
    "        model.wave_speed = c\n",
    "\n",
    "        # Front points (N)\n",
    "        t_fronts, x_fronts = model.track_wavefront_local_interpolation(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic', target='N'\n",
    "        )\n",
    "\n",
    "        # Save artifacts\n",
    "        _save_summary(run_dir, dict(\n",
    "            lambda_val=float(lam),\n",
    "            alpha=float(alpha),\n",
    "            m0=float(m0),\n",
    "            wave_speed=float(c),\n",
    "            r2=(float(r2) if r2 is not None else None),\n",
    "            # useful context\n",
    "            dt=model.dt, T=model.T, L=model.L, N=model.N,\n",
    "            init_type=model.init_type,\n",
    "            steepness=getattr(model, \"steepness\", None),\n",
    "            perc=getattr(model, \"perc\", None),\n",
    "            t_start=model.t_start, t_end=model.t_end,\n",
    "            num_points=getattr(model, \"num_points\", None),\n",
    "            saved_stride=int(snapshot_stride)\n",
    "        ))\n",
    "        _save_fronts(run_dir, t_fronts, x_fronts, name=\"N\")\n",
    "        _save_snapshots_every_stride(run_dir, model, stride=snapshot_stride)\n",
    "\n",
    "        return (\"done\", lam, alpha, m0, float(c), (float(r2) if r2 is not None else None))\n",
    "\n",
    "    except Exception as e:\n",
    "        return (\"failed\", lam, alpha, m0, str(e))\n",
    "\n",
    "# -------------------------\n",
    "# Parallel grid runner\n",
    "# -------------------------\n",
    "def run_grid(lambda_vals, alpha_vals, m0_vals,\n",
    "             base_dir=\"speeds_func\",\n",
    "             model_kwargs=None,\n",
    "             overwrite=False,\n",
    "             snapshot_stride=150,\n",
    "             n_jobs=-1, verbose=10):\n",
    "    \"\"\"\n",
    "    Launch all (λ, α, m0) runs in parallel and log failures & low-R² cases.\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    tasks = [(lam, alpha, m0) for lam in lambda_vals for alpha in alpha_vals for m0 in m0_vals]\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=verbose, backend=\"loky\")(\n",
    "        delayed(run_one)(\n",
    "            lam, alpha, m0,\n",
    "            base_dir=base_dir,\n",
    "            model_kwargs=model_kwargs,\n",
    "            overwrite=overwrite,\n",
    "            snapshot_stride=snapshot_stride\n",
    "        ) for lam, alpha, m0 in tasks\n",
    "    )\n",
    "\n",
    "    done, skipped, failed, low_r2 = [], [], [], []\n",
    "    for r in results:\n",
    "        tag = r[0]\n",
    "        if tag == \"done\":\n",
    "            _, lam, alpha_eff, m0_eff, c, r2 = r\n",
    "            done.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"c\": c, \"r2\": r2})\n",
    "            if (r2 is None) or (isinstance(r2, float) and (np.isnan(r2) or r2 < .999)):\n",
    "                low_r2.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"c\": c, \"r2\": r2})\n",
    "        elif tag == \"skipped\":\n",
    "            _, lam, alpha_eff, m0_eff = r\n",
    "            skipped.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff})\n",
    "        elif tag == \"failed\":\n",
    "            _, lam, alpha_orig, m0_orig, msg = r\n",
    "            failed.append({\"lambda\": lam, \"alpha\": alpha_orig, \"m0\": m0_orig, \"error\": msg})\n",
    "\n",
    "    base = Path(base_dir)\n",
    "    _ensure_dir(base)\n",
    "    _atomic_write_json(base / \"failed_runs.json\", failed)\n",
    "    _atomic_write_json(base / \"low_r2_runs.json\", low_r2)\n",
    "\n",
    "    print(f\"✅ Done: {len(done)}, Skipped: {len(skipped)}, Failed: {len(failed)}, Low-R²: {len(low_r2)}\")\n",
    "    if failed:\n",
    "        print(\"❌ Failed runs (sample):\")\n",
    "        for item in failed[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | error: {item['error']}\")\n",
    "    if low_r2:\n",
    "        print(\"⚠️  Low-R² runs (R² < 0.999):\")\n",
    "        for item in low_r2[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | c={item['c']} | r2={item['r2']}\")\n",
    "\n",
    "    return {\"done\": done, \"skipped\": skipped, \"failed\": failed, \"low_r2\": low_r2}\n",
    "\n",
    "# -------------------------\n",
    "# Example usage in the notebook\n",
    "# -------------------------\n",
    "# 1) Make sure you've already done:\n",
    "#    from func import Dissertation_Func_1D\n",
    "#\n",
    "# 2) Define your grids and shared kwargs:\n",
    "\n",
    "lambda_vals = [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100, 1000, 100000, 1000000, 10000000, 100000000]\n",
    "alpha_vals  = [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 100, 1000, 100000, 1000000, 10000000, 100000000]\n",
    "m0_vals     = [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, ]\n",
    "\n",
    "shared_kwargs = dict(\n",
    "    # Your requested defaults\n",
    "    L=200, N=20001, T=400, dt=0.1,\n",
    "    init_type=\"tanh\", steepness=0.85, perc=0.4,\n",
    "    t_start=100, t_end=350, num_points=250,\n",
    "    n0=1.0, K=1.0, rho=1.0, D=1.0, Mmax=1.0\n",
    ")\n",
    "\n",
    "# 3) Run the grid (tweak n_jobs as your machine allows)\n",
    "results = run_grid(lambda_vals, alpha_vals, m0_vals,                    \n",
    "                   base_dir=\"speeds_func\",\n",
    "                    model_kwargs=shared_kwargs,\n",
    "                    snapshot_stride=150,   # <- only every 150th snapshot (plus last)\n",
    "                    overwrite=False, n_jobs=8, verbose=10)\n",
    "\n",
    "# 4) (Optional) Quick flagged summary (after results) — example:\n",
    "print(\"\\n=== Summary of Problematic Runs ===\")\n",
    "for item in results[\"failed\"]:\n",
    "    print(f\"FAIL -> λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | {item['error']}\")\n",
    "for item in results[\"low_r2\"][:20]:\n",
    "    print(f\"LOW R² -> λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | r2={item['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed: 41.7min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 56.4min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed: 63.1min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed: 82.2min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed: 90.6min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed: 97.6min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 105.2min\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed: 112.8min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 121.6min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed: 130.1min\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed: 141.9min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed: 155.2min\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed: 166.3min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed: 178.1min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed: 191.2min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed: 202.4min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed: 215.0min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed: 226.5min\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed: 238.5min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed: 251.1min\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed: 265.2min\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed: 279.2min\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed: 293.5min\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed: 306.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: 975, Skipped: 0, Failed: 0, Low-R²: 147\n",
      "⚠️  Low-R² runs (R² < 0.999):\n",
      "  λ=0.001, α=0.1, m0=0 | c=0.1825422738218574 | r2=0.9939823199012505\n",
      "  λ=0.001, α=0.1, m0=0.01 | c=0.18254901365038861 | r2=0.9939817531622139\n",
      "  λ=0.001, α=0.1, m0=0.05 | c=0.18245838266681294 | r2=0.9939920615285572\n",
      "  λ=0.001, α=0.1, m0=0.1 | c=0.1820808563510841 | r2=0.9940340471360012\n",
      "  λ=0.001, α=0.1, m0=0.2 | c=0.180424092727537 | r2=0.9942266700510298\n",
      "  λ=0.001, α=0.1, m0=0.3 | c=0.17762218665941246 | r2=0.9946744215865934\n",
      "  λ=0.001, α=0.1, m0=0.4 | c=0.17429039383805775 | r2=0.9957977145424453\n",
      "  λ=0.001, α=0.1, m0=0.5 | c=0.16994869857466 | r2=0.9972079210629353\n",
      "  λ=0.001, α=0.1, m0=0.6 | c=0.16240009330638527 | r2=0.9982217199467363\n",
      "  λ=0.001, α=0.1, m0=0.7 | c=0.149694602887888 | r2=0.9988480618761971\n",
      "  λ=0.001, α=0.2, m0=0 | c=0.14554441406227098 | r2=0.9970117699364457\n",
      "  λ=0.001, α=0.2, m0=0.01 | c=0.14555348055396236 | r2=0.9970102882911462\n",
      "  λ=0.001, α=0.2, m0=0.05 | c=0.14554556741467964 | r2=0.9970136094073029\n",
      "  λ=0.001, α=0.2, m0=0.1 | c=0.14545107649271 | r2=0.9970408288809791\n",
      "  λ=0.001, α=0.2, m0=0.2 | c=0.14540009310234886 | r2=0.9973083521439315\n",
      "  λ=0.001, α=0.2, m0=0.3 | c=0.1502106279362887 | r2=0.9989384719184501\n",
      "  λ=0.001, α=0.3, m0=0 | c=0.1325643264462825 | r2=0.9983687008414331\n",
      "  λ=0.001, α=0.3, m0=0.01 | c=0.1325727280505273 | r2=0.9983672257065802\n",
      "  λ=0.001, α=0.3, m0=0.05 | c=0.13258868804704305 | r2=0.9983658460841265\n",
      "  λ=0.001, α=0.3, m0=0.1 | c=0.13259678686124116 | r2=0.9983754104674712\n",
      "\n",
      "=== Summary of Problematic Runs ===\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0 | r2=0.9939823199012505\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.01 | r2=0.9939817531622139\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.05 | r2=0.9939920615285572\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.1 | r2=0.9940340471360012\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.2 | r2=0.9942266700510298\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.3 | r2=0.9946744215865934\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.4 | r2=0.9957977145424453\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.5 | r2=0.9972079210629353\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.6 | r2=0.9982217199467363\n",
      "LOW R² -> λ=0.001, α=0.1, m0=0.7 | r2=0.9988480618761971\n",
      "LOW R² -> λ=0.001, α=0.2, m0=0 | r2=0.9970117699364457\n",
      "LOW R² -> λ=0.001, α=0.2, m0=0.01 | r2=0.9970102882911462\n",
      "LOW R² -> λ=0.001, α=0.2, m0=0.05 | r2=0.9970136094073029\n",
      "LOW R² -> λ=0.001, α=0.2, m0=0.1 | r2=0.9970408288809791\n",
      "LOW R² -> λ=0.001, α=0.2, m0=0.2 | r2=0.9973083521439315\n",
      "LOW R² -> λ=0.001, α=0.2, m0=0.3 | r2=0.9989384719184501\n",
      "LOW R² -> λ=0.001, α=0.3, m0=0 | r2=0.9983687008414331\n",
      "LOW R² -> λ=0.001, α=0.3, m0=0.01 | r2=0.9983672257065802\n",
      "LOW R² -> λ=0.001, α=0.3, m0=0.05 | r2=0.9983658460841265\n",
      "LOW R² -> λ=0.001, α=0.3, m0=0.1 | r2=0.9983754104674712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 975 out of 975 | elapsed: 312.7min finished\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1x3 row: (alpha, lambda) = (10^{-1},10^{-1}), (10^{-2},10^{-2}), (10^{-3},10^{-3})\n",
    "# Simulated U (orange) vs KPP U(ξ) (black dashed), using c from summary.json\n",
    "# ============================================\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "# ---------- LaTeX styling (safe: no unicode literals) ----------\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"axes.unicode_minus\": False,\n",
    "})\n",
    "\n",
    "# ---------- tolerant run-dir helpers ----------\n",
    "def _token_variants(v: float):\n",
    "    v = float(v)\n",
    "    dec   = f\"{v:.12f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    plain = f\"{v:g}\"\n",
    "    sci   = f\"{v:.0e}\"; s,e = sci.split(\"e\"); sci_neat = f\"{s}e{int(e)}\"\n",
    "    toks = {dec, plain, sci, sci_neat}\n",
    "    toks |= {t.replace(\".\", \"p\") for t in list(toks)}\n",
    "    return toks\n",
    "\n",
    "def _exactish_dir(parent: Path, prefix: str, value: float):\n",
    "    if not parent.exists(): return None\n",
    "    for tok in _token_variants(value):\n",
    "        p = parent / f\"{prefix}_{tok}\"\n",
    "        if p.is_dir(): return p\n",
    "    return None\n",
    "\n",
    "def find_run_dir(base_roots, lam, alpha, m0):\n",
    "    if isinstance(base_roots, (str, Path)): base_roots = (base_roots,)\n",
    "    for root in base_roots:\n",
    "        root = Path(root)\n",
    "        d1 = _exactish_dir(root, \"lambda\", lam)\n",
    "        if d1 is None: continue\n",
    "        d2 = _exactish_dir(d1, \"alpha\", alpha)\n",
    "        if d2 is None: continue\n",
    "        d3 = _exactish_dir(d2, \"m0\", m0)\n",
    "        if d3 is not None: return d3\n",
    "    return None\n",
    "\n",
    "# ---------- load c, m0 and snapshots ----------\n",
    "def load_run(run_dir: Path):\n",
    "    meta = json.loads((run_dir / \"summary.json\").read_text())\n",
    "    z = np.load(run_dir / \"snapshots.npz\", allow_pickle=True)\n",
    "    return dict(\n",
    "        c=float(meta[\"wave_speed\"]),\n",
    "        lam=float(meta.get(\"lambda_val\", meta.get(\"lambda\", np.nan))),\n",
    "        alpha=float(meta.get(\"alpha\", np.nan)),\n",
    "        m0=float(meta.get(\"m0\", np.nan)),\n",
    "        x=np.asarray(z[\"x\"], float),\n",
    "        times=np.asarray(z[\"times\"], float),\n",
    "        U=np.asarray(z.get(\"N_arr\", z.get(\"u_arr\")), float),\n",
    "    )\n",
    "\n",
    "# ---------- U=0.5 front (monotone spline) ----------\n",
    "def front_x_at_time(x, Urow, threshold=0.5, band=(0.1,0.9)):\n",
    "    mask = (Urow > band[0]) & (Urow < band[1])\n",
    "    if mask.sum() < 5: return None\n",
    "    xloc = x[mask]; uloc = Urow[mask]\n",
    "    order = np.argsort(xloc); xloc = xloc[order]; uloc = uloc[order]\n",
    "    spl = PchipInterpolator(xloc, uloc, extrapolate=True)\n",
    "    s = np.sign(uloc - threshold)\n",
    "    idx = np.where(s[:-1]*s[1:] < 0)[0]\n",
    "    if len(idx)==0: return None\n",
    "    i = idx[0]; xl, xr = xloc[i], xloc[i+1]\n",
    "    sol = root_scalar(lambda xv: spl(xv)-threshold, bracket=[xl,xr], method=\"brentq\")\n",
    "    return sol.root if sol.converged else None\n",
    "\n",
    "# ---------- robust centering around t_ref ----------\n",
    "def best_center_x(x, Uall, times, t_ref,\n",
    "                  thresholds=(0.5, 0.45, 0.55),\n",
    "                  bands=((0.1,0.9),(0.05,0.95),(0.0,1.0)),\n",
    "                  time_window=120.0):\n",
    "    dt = np.abs(times - t_ref)\n",
    "    cand = np.argsort(dt)\n",
    "    cand = [k for k in cand if dt[k] <= time_window]\n",
    "    for k in cand:\n",
    "        Urow = Uall[k]\n",
    "        for thr in thresholds:\n",
    "            for band in bands:\n",
    "                x0 = front_x_at_time(x, Urow, threshold=thr, band=band)\n",
    "                if x0 is not None:\n",
    "                    return k, x0\n",
    "    # fallback: center at domain midpoint if no clean crossing found\n",
    "    k = int(np.argmin(np.abs(times - t_ref)))\n",
    "    return k, 0.5*(x[0]+x[-1])\n",
    "\n",
    "# ---------- 10^k neat formatter ----------\n",
    "def fmt_pow10(v: float):\n",
    "    v = float(v)\n",
    "    if np.isclose(v, 1.0):  return \"1\"\n",
    "    if np.isclose(v, 10.0): return \"10\"\n",
    "    if v == 0: return \"0\"\n",
    "    k = int(np.round(np.log10(abs(v))))\n",
    "    if np.isclose(v, 10.0**k):\n",
    "        return rf\"10^{{{k}}}\"\n",
    "    mant = v/(10.0**k)\n",
    "    return rf\"{mant:.2g}\\times 10^{{{k}}}\"\n",
    "\n",
    "# ---------- KPP (constant-D) solver using c and m0 ----------\n",
    "def kpp_rhs(xi, y, c, D):\n",
    "    U, V = y\n",
    "    return [V, -(c/D)*V - (1.0/D)*U*(1.0-U)]\n",
    "\n",
    "def solve_kpp_ivp(c, m0, L=40.0, epsL=1e-6, epsR=1e-8,\n",
    "                  solver=\"Radau\", rtol=1e-8, atol=1e-11, max_step=0.05):\n",
    "    D = float(m0*(1.0-m0))\n",
    "    # back-tail decay rate (linearized near U≈1)\n",
    "    r = (-c + np.sqrt(c*c + 4.0*D)) / (2.0*D)\n",
    "    U0, V0 = 1.0-epsL, -r*epsL\n",
    "\n",
    "    def hit_tip(xi, y): return y[0] - epsR\n",
    "    hit_tip.terminal = True; hit_tip.direction = -1\n",
    "\n",
    "    sol = solve_ivp(lambda x,y: kpp_rhs(x, y, c, D),\n",
    "                    t_span=(-L, +L), y0=[U0, V0],\n",
    "                    method=solver, rtol=rtol, atol=atol,\n",
    "                    max_step=max_step, events=hit_tip)\n",
    "    return sol.t, sol.y[0]\n",
    "\n",
    "# ---------- 1×3 row plot ----------\n",
    "def row_sim_vs_kpp_same_exponents(base_roots, exponents=(-1, -2, -3),\n",
    "                                  m0=0.5, t_ref=100,\n",
    "                                  time_window=120.0,\n",
    "                                  xi_span_factor=12.0,  # ±(xi_span_factor*c)\n",
    "                                  xi_min_span=15.0,     # at least ±this\n",
    "                                  tumor_color=\"#ff8c00\",\n",
    "                                  kpp_style={\"color\":\"k\",\"ls\":\"--\",\"lw\":2.2},\n",
    "                                  figsize=(12, 4.5),\n",
    "                                  tick_fs=12, label_fs=14, title_fs=15):\n",
    "    ncols = len(exponents)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=figsize, sharex=True, sharey=True)\n",
    "    if ncols == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    legend_handles = None\n",
    "\n",
    "    for j, e in enumerate(exponents):\n",
    "        ax = axes[j]\n",
    "        lam = 10.0**e\n",
    "        alpha = 10.0**e\n",
    "\n",
    "        run_dir = find_run_dir(base_roots, lam, alpha, m0)\n",
    "        if run_dir is None:\n",
    "            ax.text(0.5, 0.5, \"(run not found)\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "            ax.set_axis_off()\n",
    "            continue\n",
    "\n",
    "        data = load_run(run_dir)\n",
    "        c, x, T, Uall = data[\"c\"], data[\"x\"], data[\"times\"], data[\"U\"]\n",
    "        k, x0 = best_center_x(x, Uall, T, t_ref, time_window=time_window)\n",
    "        xi_num = x - x0\n",
    "\n",
    "        # choose ξ half-span\n",
    "        xi_half = max(xi_span_factor*abs(c), xi_min_span)\n",
    "\n",
    "        # KPP line (integrate a bit beyond displayed window)\n",
    "        xi_kpp, U_kpp = solve_kpp_ivp(c, m0, L=xi_half*1.15)\n",
    "\n",
    "        l1, = ax.plot(xi_num, Uall[k], color=tumor_color, lw=2.4, alpha=0.9, label=r\"$U$ (simulated)\")\n",
    "        l2, = ax.plot(xi_kpp, U_kpp, label=r\"$U(\\xi)$ (KPP)\", **kpp_style)\n",
    "\n",
    "        if legend_handles is None:\n",
    "            legend_handles = (l1, l2)\n",
    "\n",
    "        ax.set_xlim(-xi_half, +xi_half)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.grid(True, ls=\"--\", alpha=0.25)\n",
    "        ax.tick_params(labelsize=tick_fs)\n",
    "\n",
    "        ax.set_title(rf\"$\\alpha={fmt_pow10(alpha)}$, $\\lambda={fmt_pow10(lam)}$\", fontsize=title_fs)\n",
    "\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(r\"$U(\\xi)$\", fontsize=label_fs)\n",
    "        ax.set_xlabel(r\"$\\xi$\", fontsize=label_fs)\n",
    "\n",
    "    if legend_handles is not None:\n",
    "        fig.legend(legend_handles, [h.get_label() for h in legend_handles],\n",
    "                   loc=\"center left\", bbox_to_anchor=(1.01, 0.5),\n",
    "                   frameon=False, fontsize=12)\n",
    "\n",
    "    fig.tight_layout(rect=[0.05, 0.05, 0.88, 0.95])\n",
    "    plt.show()\n",
    "    return fig, axes\n",
    "\n",
    "# ------------------------------\n",
    "# Example call\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    BASES = (\"speeds_func_4\", \"speeds_func_l\", \"speeds_func_u\")\n",
    "    row_sim_vs_kpp_same_exponents(\n",
    "        base_roots=BASES,\n",
    "        exponents=(-1, -2, -3),  # columns: 10^{-1}, 10^{-2}, 10^{-3}\n",
    "        m0=0.5,\n",
    "        t_ref=100,               # target time; code searches ±120 for a clean crossing\n",
    "        time_window=120.0,\n",
    "        xi_span_factor=12.0,\n",
    "        xi_min_span=15.0\n",
    "    )# ============================================\n",
    "# 1x3 row: (alpha, lambda) = (10^{-1},10^{-1}), (10^{-2},10^{-2}), (10^{-3},10^{-3})\n",
    "# Simulated U (orange) vs KPP U(ξ) (black dashed), using c from summary.json\n",
    "# ============================================\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "# ---------- LaTeX styling (safe: no unicode literals) ----------\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"axes.unicode_minus\": False,\n",
    "})\n",
    "\n",
    "# ---------- tolerant run-dir helpers ----------\n",
    "def _token_variants(v: float):\n",
    "    v = float(v)\n",
    "    dec   = f\"{v:.12f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    plain = f\"{v:g}\"\n",
    "    sci   = f\"{v:.0e}\"; s,e = sci.split(\"e\"); sci_neat = f\"{s}e{int(e)}\"\n",
    "    toks = {dec, plain, sci, sci_neat}\n",
    "    toks |= {t.replace(\".\", \"p\") for t in list(toks)}\n",
    "    return toks\n",
    "\n",
    "def _exactish_dir(parent: Path, prefix: str, value: float):\n",
    "    if not parent.exists(): return None\n",
    "    for tok in _token_variants(value):\n",
    "        p = parent / f\"{prefix}_{tok}\"\n",
    "        if p.is_dir(): return p\n",
    "    return None\n",
    "\n",
    "def find_run_dir(base_roots, lam, alpha, m0):\n",
    "    if isinstance(base_roots, (str, Path)): base_roots = (base_roots,)\n",
    "    for root in base_roots:\n",
    "        root = Path(root)\n",
    "        d1 = _exactish_dir(root, \"lambda\", lam)\n",
    "        if d1 is None: continue\n",
    "        d2 = _exactish_dir(d1, \"alpha\", alpha)\n",
    "        if d2 is None: continue\n",
    "        d3 = _exactish_dir(d2, \"m0\", m0)\n",
    "        if d3 is not None: return d3\n",
    "    return None\n",
    "\n",
    "# ---------- load c, m0 and snapshots ----------\n",
    "def load_run(run_dir: Path):\n",
    "    meta = json.loads((run_dir / \"summary.json\").read_text())\n",
    "    z = np.load(run_dir / \"snapshots.npz\", allow_pickle=True)\n",
    "    return dict(\n",
    "        c=float(meta[\"wave_speed\"]),\n",
    "        lam=float(meta.get(\"lambda_val\", meta.get(\"lambda\", np.nan))),\n",
    "        alpha=float(meta.get(\"alpha\", np.nan)),\n",
    "        m0=float(meta.get(\"m0\", np.nan)),\n",
    "        x=np.asarray(z[\"x\"], float),\n",
    "        times=np.asarray(z[\"times\"], float),\n",
    "        U=np.asarray(z.get(\"N_arr\", z.get(\"u_arr\")), float),\n",
    "    )\n",
    "\n",
    "# ---------- U=0.5 front (monotone spline) ----------\n",
    "def front_x_at_time(x, Urow, threshold=0.5, band=(0.1,0.9)):\n",
    "    mask = (Urow > band[0]) & (Urow < band[1])\n",
    "    if mask.sum() < 5: return None\n",
    "    xloc = x[mask]; uloc = Urow[mask]\n",
    "    order = np.argsort(xloc); xloc = xloc[order]; uloc = uloc[order]\n",
    "    spl = PchipInterpolator(xloc, uloc, extrapolate=True)\n",
    "    s = np.sign(uloc - threshold)\n",
    "    idx = np.where(s[:-1]*s[1:] < 0)[0]\n",
    "    if len(idx)==0: return None\n",
    "    i = idx[0]; xl, xr = xloc[i], xloc[i+1]\n",
    "    sol = root_scalar(lambda xv: spl(xv)-threshold, bracket=[xl,xr], method=\"brentq\")\n",
    "    return sol.root if sol.converged else None\n",
    "\n",
    "# ---------- robust centering around t_ref ----------\n",
    "def best_center_x(x, Uall, times, t_ref,\n",
    "                  thresholds=(0.5, 0.45, 0.55),\n",
    "                  bands=((0.1,0.9),(0.05,0.95),(0.0,1.0)),\n",
    "                  time_window=120.0):\n",
    "    dt = np.abs(times - t_ref)\n",
    "    cand = np.argsort(dt)\n",
    "    cand = [k for k in cand if dt[k] <= time_window]\n",
    "    for k in cand:\n",
    "        Urow = Uall[k]\n",
    "        for thr in thresholds:\n",
    "            for band in bands:\n",
    "                x0 = front_x_at_time(x, Urow, threshold=thr, band=band)\n",
    "                if x0 is not None:\n",
    "                    return k, x0\n",
    "    # fallback: center at domain midpoint if no clean crossing found\n",
    "    k = int(np.argmin(np.abs(times - t_ref)))\n",
    "    return k, 0.5*(x[0]+x[-1])\n",
    "\n",
    "# ---------- 10^k neat formatter ----------\n",
    "def fmt_pow10(v: float):\n",
    "    v = float(v)\n",
    "    if np.isclose(v, 1.0):  return \"1\"\n",
    "    if np.isclose(v, 10.0): return \"10\"\n",
    "    if v == 0: return \"0\"\n",
    "    k = int(np.round(np.log10(abs(v))))\n",
    "    if np.isclose(v, 10.0**k):\n",
    "        return rf\"10^{{{k}}}\"\n",
    "    mant = v/(10.0**k)\n",
    "    return rf\"{mant:.2g}\\times 10^{{{k}}}\"\n",
    "\n",
    "# ---------- KPP (constant-D) solver using c and m0 ----------\n",
    "def kpp_rhs(xi, y, c, D):\n",
    "    U, V = y\n",
    "    return [V, -(c/D)*V - (1.0/D)*U*(1.0-U)]\n",
    "\n",
    "def solve_kpp_ivp(c, m0, L=40.0, epsL=1e-6, epsR=1e-8,\n",
    "                  solver=\"Radau\", rtol=1e-8, atol=1e-11, max_step=0.05):\n",
    "    D = float(m0*(1.0-m0))\n",
    "    # back-tail decay rate (linearized near U≈1)\n",
    "    r = (-c + np.sqrt(c*c + 4.0*D)) / (2.0*D)\n",
    "    U0, V0 = 1.0-epsL, -r*epsL\n",
    "\n",
    "    def hit_tip(xi, y): return y[0] - epsR\n",
    "    hit_tip.terminal = True; hit_tip.direction = -1\n",
    "\n",
    "    sol = solve_ivp(lambda x,y: kpp_rhs(x, y, c, D),\n",
    "                    t_span=(-L, +L), y0=[U0, V0],\n",
    "                    method=solver, rtol=rtol, atol=atol,\n",
    "                    max_step=max_step, events=hit_tip)\n",
    "    return sol.t, sol.y[0]\n",
    "\n",
    "# ---------- 1×3 row plot ----------\n",
    "def row_sim_vs_kpp_same_exponents(base_roots, exponents=(-1, -2, -3),\n",
    "                                  m0=0.5, t_ref=100,\n",
    "                                  time_window=120.0,\n",
    "                                  xi_span_factor=12.0,  # ±(xi_span_factor*c)\n",
    "                                  xi_min_span=15.0,     # at least ±this\n",
    "                                  tumor_color=\"#ff8c00\",\n",
    "                                  kpp_style={\"color\":\"k\",\"ls\":\"--\",\"lw\":2.2},\n",
    "                                  figsize=(12, 4.5),\n",
    "                                  tick_fs=12, label_fs=14, title_fs=15):\n",
    "    ncols = len(exponents)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=figsize, sharex=True, sharey=True)\n",
    "    if ncols == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    legend_handles = None\n",
    "\n",
    "    for j, e in enumerate(exponents):\n",
    "        ax = axes[j]\n",
    "        lam = 10.0**e\n",
    "        alpha = 10.0**e\n",
    "\n",
    "        run_dir = find_run_dir(base_roots, lam, alpha, m0)\n",
    "        if run_dir is None:\n",
    "            ax.text(0.5, 0.5, \"(run not found)\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "            ax.set_axis_off()\n",
    "            continue\n",
    "\n",
    "        data = load_run(run_dir)\n",
    "        c, x, T, Uall = data[\"c\"], data[\"x\"], data[\"times\"], data[\"U\"]\n",
    "        k, x0 = best_center_x(x, Uall, T, t_ref, time_window=time_window)\n",
    "        xi_num = x - x0\n",
    "\n",
    "        # choose ξ half-span\n",
    "        xi_half = max(xi_span_factor*abs(c), xi_min_span)\n",
    "\n",
    "        # KPP line (integrate a bit beyond displayed window)\n",
    "        xi_kpp, U_kpp = solve_kpp_ivp(c, m0, L=xi_half*1.15)\n",
    "\n",
    "        l1, = ax.plot(xi_num, Uall[k], color=tumor_color, lw=2.4, alpha=0.9, label=r\"$U$ (simulated)\")\n",
    "        l2, = ax.plot(xi_kpp, U_kpp, label=r\"$U(\\xi)$ (KPP)\", **kpp_style)\n",
    "\n",
    "        if legend_handles is None:\n",
    "            legend_handles = (l1, l2)\n",
    "\n",
    "        ax.set_xlim(-xi_half, +xi_half)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.grid(True, ls=\"--\", alpha=0.25)\n",
    "        ax.tick_params(labelsize=tick_fs)\n",
    "\n",
    "        ax.set_title(rf\"$\\alpha={fmt_pow10(alpha)}$, $\\lambda={fmt_pow10(lam)}$\", fontsize=title_fs)\n",
    "\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(r\"$U(\\xi)$\", fontsize=label_fs)\n",
    "        ax.set_xlabel(r\"$\\xi$\", fontsize=label_fs)\n",
    "\n",
    "    if legend_handles is not None:\n",
    "        fig.legend(legend_handles, [h.get_label() for h in legend_handles],\n",
    "                   loc=\"center left\", bbox_to_anchor=(1.01, 0.5),\n",
    "                   frameon=False, fontsize=12)\n",
    "\n",
    "    fig.tight_layout(rect=[0.05, 0.05, 0.88, 0.95])\n",
    "    plt.show()\n",
    "    return fig, axes\n",
    "\n",
    "# ------------------------------\n",
    "# Example call\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    BASES = (\"speeds_func_4\", \"speeds_func_l\", \"speeds_func_u\")\n",
    "    row_sim_vs_kpp_same_exponents(\n",
    "        base_roots=BASES,\n",
    "        exponents=(-1, -2, -3),  # columns: 10^{-1}, 10^{-2}, 10^{-3}\n",
    "        m0=0.5,\n",
    "        t_ref=100,               # target time; code searches ±120 for a clean crossing\n",
    "        time_window=120.0,\n",
    "        xi_span_factor=12.0,\n",
    "        xi_min_span=15.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   2 out of   6 | elapsed:  2.7min remaining:  5.5min\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   6 | elapsed:  2.7min remaining:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done   4 out of   6 | elapsed:  2.7min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: 6, Skipped: 0, Failed: 0, Low-R²: 2\n",
      "⚠️  Low-R² runs (R² < 0.999):\n",
      "  λ=0.0001, α=0.1, m0=0.5 | c=0.16994178908803234 | r2=0.9972097066131171\n",
      "  λ=1e-05, α=0.1, m0=0.5 | c=0.16994115453915076 | r2=0.9972098645032523\n",
      "\n",
      "=== Summary of Problematic Runs ===\n",
      "LOW R² -> λ=0.0001, α=0.1, m0=0.5 | r2=0.9972097066131171\n",
      "LOW R² -> λ=1e-05, α=0.1, m0=0.5 | r2=0.9972098645032523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of   6 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "# ==== Imports ====\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# -------------------------\n",
    "# Save / path helpers\n",
    "# -------------------------\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _atomic_write_json(path: Path, obj):\n",
    "    tmp = path.with_suffix(\".tmp\")\n",
    "    with open(tmp, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def _save_summary(run_dir: Path, meta: dict):\n",
    "    with open(run_dir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "def _save_fronts(run_dir: Path, t_fronts, x_fronts, name=None):\n",
    "    fname = \"fronts.npz\" if not name else f\"fronts_{name}.npz\"\n",
    "    np.savez_compressed(run_dir / fname,\n",
    "                        t_fronts=np.asarray(t_fronts),\n",
    "                        x_fronts=np.asarray(x_fronts))\n",
    "\n",
    "def _save_snapshots_every_stride(run_dir: Path, model, stride=150):\n",
    "    \"\"\"\n",
    "    Save EVERY `stride`-th snapshot (plus the last one), with U and M kept separate.\n",
    "    \"\"\"\n",
    "    idx = np.unique(np.concatenate([\n",
    "        np.arange(0, model.Nt, stride),\n",
    "        np.array([model.Nt - 1])\n",
    "    ]))\n",
    "    np.savez_compressed(\n",
    "        run_dir / \"snapshots.npz\",\n",
    "        x=model.x,\n",
    "        times=model.times[idx],\n",
    "        N_arr=model.N_arr[idx, :],   # tumour u(x,t)\n",
    "        M_arr=model.M_arr[idx, :]    # ECM   m(x,t)\n",
    "    )\n",
    "\n",
    "def _fmt_val(v):\n",
    "    # compact label in folder names: keeps ints clean (e.g., 10 not 10.0)\n",
    "    if isinstance(v, (int, np.integer)) or (isinstance(v, float) and v.is_integer()):\n",
    "        return f\"{int(v)}\"\n",
    "    s = f\"{v}\"\n",
    "    return s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "\n",
    "# -------------------------\n",
    "# Single-run worker\n",
    "# -------------------------\n",
    "def run_one(lam, alpha, m0,\n",
    "            base_dir=\"speeds_func\",\n",
    "            model_kwargs=None,\n",
    "            overwrite=False,\n",
    "            snapshot_stride=150):\n",
    "    \"\"\"\n",
    "    Builds, solves, measures, and saves one (λ, α, m0) run.\n",
    "\n",
    "    Skips a run if base_dir/lambda_*/alpha_*/m0_*/summary.json exists and overwrite=False.\n",
    "    Saves:\n",
    "      - summary.json (metadata + c, R^2)\n",
    "      - fronts.npz    (t_fronts, x_fronts for N at threshold 0.5)\n",
    "      - snapshots.npz (x, times[idx], N_arr[idx,:], M_arr[idx,:]) with idx every `snapshot_stride`\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    try:\n",
    "        # Shallow copy of shared kwargs\n",
    "        local_kwargs = dict(model_kwargs)\n",
    "\n",
    "        # Optional per-λ overrides (example: finer time-step for very large λ, if you want)\n",
    "        # if float(lam) >= 1e3:\n",
    "        #     local_kwargs.update(dict(dt=0.01))\n",
    "\n",
    "        base = Path(base_dir)\n",
    "        lam_dir = base / f\"lambda_{_fmt_val(lam)}\"\n",
    "        alpha_dir = lam_dir / f\"alpha_{_fmt_val(alpha)}\"\n",
    "        run_dir = alpha_dir / f\"m0_{_fmt_val(m0)}\"\n",
    "        _ensure_dir(run_dir)\n",
    "\n",
    "        # Skip if already done (unless overwrite=True)\n",
    "        if not overwrite and (run_dir / \"summary.json\").exists():\n",
    "            return (\"skipped\", lam, alpha, m0)\n",
    "\n",
    "        # Avoid thread over-subscription (OpenMP/BLAS)\n",
    "        os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "        # Build and solve\n",
    "        model = Dissertation_Func_1D(k=lam, alpha=alpha, m0=m0, **local_kwargs)\n",
    "        model.solve()\n",
    "\n",
    "        # Speed on u (N)\n",
    "        c, b, r2 = model.estimate_wave_speed(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic',\n",
    "            plot=False, target='N'\n",
    "        )\n",
    "        if (c is None) or (isinstance(c, float) and np.isnan(c)):\n",
    "            raise ValueError(\"Wave speed could not be calculated.\")\n",
    "        model.wave_speed = c\n",
    "\n",
    "        # Front points (N)\n",
    "        t_fronts, x_fronts = model.track_wavefront_local_interpolation(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic', target='N'\n",
    "        )\n",
    "\n",
    "        # Save artifacts\n",
    "        _save_summary(run_dir, dict(\n",
    "            lambda_val=float(lam),\n",
    "            alpha=float(alpha),\n",
    "            m0=float(m0),\n",
    "            wave_speed=float(c),\n",
    "            r2=(float(r2) if r2 is not None else None),\n",
    "            # useful context\n",
    "            dt=model.dt, T=model.T, L=model.L, N=model.N,\n",
    "            init_type=model.init_type,\n",
    "            steepness=getattr(model, \"steepness\", None),\n",
    "            perc=getattr(model, \"perc\", None),\n",
    "            t_start=model.t_start, t_end=model.t_end,\n",
    "            num_points=getattr(model, \"num_points\", None),\n",
    "            saved_stride=int(snapshot_stride)\n",
    "        ))\n",
    "        _save_fronts(run_dir, t_fronts, x_fronts, name=\"N\")\n",
    "        _save_snapshots_every_stride(run_dir, model, stride=snapshot_stride)\n",
    "\n",
    "        return (\"done\", lam, alpha, m0, float(c), (float(r2) if r2 is not None else None))\n",
    "\n",
    "    except Exception as e:\n",
    "        return (\"failed\", lam, alpha, m0, str(e))\n",
    "\n",
    "# -------------------------\n",
    "# Parallel grid runner\n",
    "# -------------------------\n",
    "def run_grid(lambda_vals, alpha_vals, m0_vals,\n",
    "             base_dir=\"speeds_func\",\n",
    "             model_kwargs=None,\n",
    "             overwrite=False,\n",
    "             snapshot_stride=150,\n",
    "             n_jobs=-1, verbose=10):\n",
    "    \"\"\"\n",
    "    Launch all (λ, α, m0) runs in parallel and log failures & low-R² cases.\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    tasks = [(lam, alpha, m0) for lam in lambda_vals for alpha in alpha_vals for m0 in m0_vals]\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=verbose, backend=\"loky\")(\n",
    "        delayed(run_one)(\n",
    "            lam, alpha, m0,\n",
    "            base_dir=base_dir,\n",
    "            model_kwargs=model_kwargs,\n",
    "            overwrite=overwrite,\n",
    "            snapshot_stride=snapshot_stride\n",
    "        ) for lam, alpha, m0 in tasks\n",
    "    )\n",
    "\n",
    "    done, skipped, failed, low_r2 = [], [], [], []\n",
    "    for r in results:\n",
    "        tag = r[0]\n",
    "        if tag == \"done\":\n",
    "            _, lam, alpha_eff, m0_eff, c, r2 = r\n",
    "            done.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"c\": c, \"r2\": r2})\n",
    "            if (r2 is None) or (isinstance(r2, float) and (np.isnan(r2) or r2 < .999)):\n",
    "                low_r2.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"c\": c, \"r2\": r2})\n",
    "        elif tag == \"skipped\":\n",
    "            _, lam, alpha_eff, m0_eff = r\n",
    "            skipped.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff})\n",
    "        elif tag == \"failed\":\n",
    "            _, lam, alpha_orig, m0_orig, msg = r\n",
    "            failed.append({\"lambda\": lam, \"alpha\": alpha_orig, \"m0\": m0_orig, \"error\": msg})\n",
    "\n",
    "    base = Path(base_dir)\n",
    "    _ensure_dir(base)\n",
    "    _atomic_write_json(base / \"failed_runs.json\", failed)\n",
    "    _atomic_write_json(base / \"low_r2_runs.json\", low_r2)\n",
    "\n",
    "    print(f\"✅ Done: {len(done)}, Skipped: {len(skipped)}, Failed: {len(failed)}, Low-R²: {len(low_r2)}\")\n",
    "    if failed:\n",
    "        print(\"❌ Failed runs (sample):\")\n",
    "        for item in failed[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | error: {item['error']}\")\n",
    "    if low_r2:\n",
    "        print(\"⚠️  Low-R² runs (R² < 0.999):\")\n",
    "        for item in low_r2[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | c={item['c']} | r2={item['r2']}\")\n",
    "\n",
    "    return {\"done\": done, \"skipped\": skipped, \"failed\": failed, \"low_r2\": low_r2}\n",
    "\n",
    "# -------------------------\n",
    "# Example usage in the notebook\n",
    "# -------------------------\n",
    "# 1) Make sure you've already done:\n",
    "#    from func import Dissertation_Func_1D\n",
    "#\n",
    "# 2) Define your grids and shared kwargs:\n",
    "\n",
    "lambda_vals = [1e-4,1e-5]\n",
    "alpha_vals  = [1e-3,1e-2,1e-1]\n",
    "m0_vals     = [0.5]\n",
    "\n",
    "shared_kwargs = dict(\n",
    "    # Your requested defaults\n",
    "    L=200, N=20001, T=400, dt=0.1,\n",
    "    init_type=\"tanh\", steepness=0.85, perc=0.4,\n",
    "    t_start=100, t_end=350, num_points=250,\n",
    "    n0=1.0, K=1.0, rho=1.0, D=1.0, Mmax=1.0\n",
    ")\n",
    "\n",
    "# 3) Run the grid (tweak n_jobs as your machine allows)\n",
    "results = run_grid(lambda_vals, alpha_vals, m0_vals,                    \n",
    "                   base_dir=\"speeds_func_tiny2\",\n",
    "                    model_kwargs=shared_kwargs,\n",
    "                    snapshot_stride=150,   # <- only every 150th snapshot (plus last)\n",
    "                    overwrite=False, n_jobs=8, verbose=10)\n",
    "\n",
    "# 4) (Optional) Quick flagged summary (after results) — example:\n",
    "print(\"\\n=== Summary of Problematic Runs ===\")\n",
    "for item in results[\"failed\"]:\n",
    "    print(f\"FAIL -> λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | {item['error']}\")\n",
    "for item in results[\"low_r2\"][:20]:\n",
    "    print(f\"LOW R² -> λ={item['lambda']}, α={item['alpha']}, m0={item['m0']} | r2={item['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-2)]: Done  11 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-2)]: Done  27 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-2)]: Done  47 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-2)]: Done  71 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-2)]: Done  84 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-2)]: Done  99 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=-2)]: Done 114 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-2)]: Done 131 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed: 70.3min\n",
      "[Parallel(n_jobs=-2)]: Done 167 tasks      | elapsed: 77.1min\n",
      "[Parallel(n_jobs=-2)]: Done 186 tasks      | elapsed: 87.2min\n",
      "[Parallel(n_jobs=-2)]: Done 207 tasks      | elapsed: 98.0min\n",
      "[Parallel(n_jobs=-2)]: Done 228 tasks      | elapsed: 108.2min\n",
      "[Parallel(n_jobs=-2)]: Done 251 tasks      | elapsed: 119.4min\n",
      "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed: 131.0min\n",
      "[Parallel(n_jobs=-2)]: Done 299 tasks      | elapsed: 139.6min\n",
      "[Parallel(n_jobs=-2)]: Done 324 tasks      | elapsed: 154.3min\n",
      "[Parallel(n_jobs=-2)]: Done 351 tasks      | elapsed: 165.3min\n",
      "[Parallel(n_jobs=-2)]: Done 378 tasks      | elapsed: 176.5min\n",
      "[Parallel(n_jobs=-2)]: Done 407 tasks      | elapsed: 189.5min\n",
      "[Parallel(n_jobs=-2)]: Done 436 tasks      | elapsed: 201.5min\n",
      "[Parallel(n_jobs=-2)]: Done 467 tasks      | elapsed: 215.9min\n",
      "[Parallel(n_jobs=-2)]: Done 498 tasks      | elapsed: 229.8min\n",
      "[Parallel(n_jobs=-2)]: Done 531 tasks      | elapsed: 244.4min\n",
      "[Parallel(n_jobs=-2)]: Done 564 tasks      | elapsed: 258.5min\n",
      "[Parallel(n_jobs=-2)]: Done 599 tasks      | elapsed: 276.7min\n",
      "[Parallel(n_jobs=-2)]: Done 634 tasks      | elapsed: 293.8min\n",
      "[Parallel(n_jobs=-2)]: Done 671 tasks      | elapsed: 314.1min\n",
      "[Parallel(n_jobs=-2)]: Done 708 tasks      | elapsed: 333.3min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 226\u001b[39m\n\u001b[32m    216\u001b[39m shared_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# Your requested defaults\u001b[39;00m\n\u001b[32m    218\u001b[39m     L=\u001b[32m200\u001b[39m, N=\u001b[32m20001\u001b[39m, T=\u001b[32m400\u001b[39m, dt=\u001b[32m0.1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    222\u001b[39m     K=\u001b[32m1.0\u001b[39m, rho=\u001b[32m1.0\u001b[39m, D=\u001b[32m1.0\u001b[39m, Mmax=\u001b[32m1.0\u001b[39m\n\u001b[32m    223\u001b[39m )\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# 3) Run the grid (tweak n_jobs as your machine allows)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m results = \u001b[43mrun_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn0_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspeeds_func_u0_mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshared_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msnapshot_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# <- only every 150th snapshot (plus last)\u001b[39;49;00m\n\u001b[32m    230\u001b[39m \u001b[43m                   \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# 4) (Optional) Quick flagged summary (after results) — example:\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Summary of Problematic Runs ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 161\u001b[39m, in \u001b[36mrun_grid\u001b[39m\u001b[34m(lambda_vals, alpha_vals, m0_vals, n0_vals, base_dir, model_kwargs, overwrite, snapshot_stride, n_jobs, verbose)\u001b[39m\n\u001b[32m    153\u001b[39m     model_kwargs = {}\n\u001b[32m    155\u001b[39m tasks = [(lam, alpha, m0, n0)\n\u001b[32m    156\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m lam \u001b[38;5;129;01min\u001b[39;00m lambda_vals\n\u001b[32m    157\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alpha_vals\n\u001b[32m    158\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m m0 \u001b[38;5;129;01min\u001b[39;00m m0_vals\n\u001b[32m    159\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m n0 \u001b[38;5;129;01min\u001b[39;00m n0_vals]\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mloky\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_one\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43msnapshot_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43msnapshot_stride\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m done, skipped, failed, low_r2 = [], [], [], []\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oxford/Dissertation/Main/venv/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oxford/Dissertation/Main/venv/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oxford/Dissertation/Main/venv/lib/python3.11/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==== Imports ====\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# -------------------------\n",
    "# Save / path helpers\n",
    "# -------------------------\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _atomic_write_json(path: Path, obj):\n",
    "    tmp = path.with_suffix(\".tmp\")\n",
    "    with open(tmp, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def _save_summary(run_dir: Path, meta: dict):\n",
    "    with open(run_dir / \"summary.json\", \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "def _save_fronts(run_dir: Path, t_fronts, x_fronts, name=None):\n",
    "    fname = \"fronts.npz\" if not name else f\"fronts_{name}.npz\"\n",
    "    np.savez_compressed(run_dir / fname,\n",
    "                        t_fronts=np.asarray(t_fronts),\n",
    "                        x_fronts=np.asarray(x_fronts))\n",
    "\n",
    "def _save_snapshots_every_stride(run_dir: Path, model, stride=150):\n",
    "    \"\"\"\n",
    "    Save EVERY `stride`-th snapshot (plus the last one), with U and M kept separate.\n",
    "    \"\"\"\n",
    "    idx = np.unique(np.concatenate([\n",
    "        np.arange(0, model.Nt, stride),\n",
    "        np.array([model.Nt - 1])\n",
    "    ]))\n",
    "    np.savez_compressed(\n",
    "        run_dir / \"snapshots.npz\",\n",
    "        x=model.x,\n",
    "        times=model.times[idx],\n",
    "        N_arr=model.N_arr[idx, :],   # tumour u(x,t)\n",
    "        M_arr=model.M_arr[idx, :]    # ECM   m(x,t)\n",
    "    )\n",
    "\n",
    "def _fmt_val(v):\n",
    "    # compact label in folder names: keeps ints clean (e.g., 10 not 10.0)\n",
    "    if isinstance(v, (int, np.integer)) or (isinstance(v, float) and float(v).is_integer()):\n",
    "        return f\"{int(v)}\"\n",
    "    s = f\"{v}\"\n",
    "    return s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "\n",
    "# -------------------------\n",
    "# Single-run worker\n",
    "# -------------------------\n",
    "def run_one(lam, alpha, m0, n0,\n",
    "            base_dir=\"speeds_func\",\n",
    "            model_kwargs=None,\n",
    "            overwrite=False,\n",
    "            snapshot_stride=150):\n",
    "    \"\"\"\n",
    "    Builds, solves, measures, and saves one (λ, α, m0, n0) run.\n",
    "\n",
    "    Skips a run if base_dir/lambda_*/alpha_*/m0_*/n0_*/summary.json exists and overwrite=False.\n",
    "    Saves:\n",
    "      - summary.json (metadata + c, R^2)\n",
    "      - fronts_N.npz  (t_fronts, x_fronts for N at threshold 0.5)\n",
    "      - snapshots.npz (x, times[idx], N_arr[idx,:], M_arr[idx,:]) with idx every `snapshot_stride`\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    try:\n",
    "        # Shallow copy of shared kwargs\n",
    "        local_kwargs = dict(model_kwargs)\n",
    "        # Ensure per-run n0 overrides the shared one\n",
    "        local_kwargs[\"n0\"] = float(n0)\n",
    "\n",
    "        base = Path(base_dir)\n",
    "        lam_dir   = base / f\"lambda_{_fmt_val(lam)}\"\n",
    "        alpha_dir = lam_dir / f\"alpha_{_fmt_val(alpha)}\"\n",
    "        m0_dir    = alpha_dir / f\"m0_{_fmt_val(m0)}\"\n",
    "        run_dir   = m0_dir / f\"n0_{_fmt_val(n0)}\"\n",
    "        _ensure_dir(run_dir)\n",
    "\n",
    "        # Skip if already done (unless overwrite=True)\n",
    "        if not overwrite and (run_dir / \"summary.json\").exists():\n",
    "            return (\"skipped\", lam, alpha, m0, n0)\n",
    "\n",
    "        # Avoid thread over-subscription (OpenMP/BLAS)\n",
    "        os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "        # Build and solve\n",
    "        # NOTE: import your model in the caller's environment:\n",
    "        # from func import Dissertation_Func_1D\n",
    "        model = Dissertation_Func_1D(k=lam, alpha=alpha, m0=m0, **local_kwargs)\n",
    "        model.solve()\n",
    "\n",
    "        # Speed on u (N)\n",
    "        c, b, r2 = model.estimate_wave_speed(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic',\n",
    "            plot=False, target='N'\n",
    "        )\n",
    "        if (c is None) or (isinstance(c, float) and np.isnan(c)):\n",
    "            raise ValueError(\"Wave speed could not be calculated.\")\n",
    "        model.wave_speed = c\n",
    "\n",
    "        # Front points (N)\n",
    "        t_fronts, x_fronts = model.track_wavefront_local_interpolation(\n",
    "            threshold=0.5, band=(0.1, 0.9), spline_type='cubic', target='N'\n",
    "        )\n",
    "\n",
    "        # Save artifacts\n",
    "        _save_summary(run_dir, dict(\n",
    "            lambda_val=float(lam),\n",
    "            alpha=float(alpha),\n",
    "            m0=float(m0),\n",
    "            n0=float(n0),\n",
    "            wave_speed=float(c),\n",
    "            r2=(float(r2) if r2 is not None else None),\n",
    "            # useful context\n",
    "            dt=model.dt, T=model.T, L=model.L, N=model.N,\n",
    "            init_type=model.init_type,\n",
    "            steepness=getattr(model, \"steepness\", None),\n",
    "            perc=getattr(model, \"perc\", None),\n",
    "            t_start=model.t_start, t_end=model.t_end,\n",
    "            num_points=getattr(model, \"num_points\", None),\n",
    "            saved_stride=int(snapshot_stride)\n",
    "        ))\n",
    "        _save_fronts(run_dir, t_fronts, x_fronts, name=\"N\")\n",
    "        _save_snapshots_every_stride(run_dir, model, stride=snapshot_stride)\n",
    "\n",
    "        return (\"done\", lam, alpha, m0, n0, float(c), (float(r2) if r2 is not None else None))\n",
    "\n",
    "    except Exception as e:\n",
    "        return (\"failed\", lam, alpha, m0, n0, str(e))\n",
    "\n",
    "# -------------------------\n",
    "# Parallel grid runner\n",
    "# -------------------------\n",
    "def run_grid(lambda_vals, alpha_vals, m0_vals, n0_vals,\n",
    "             base_dir=\"speeds_func\",\n",
    "             model_kwargs=None,\n",
    "             overwrite=False,\n",
    "             snapshot_stride=150,\n",
    "             n_jobs=-1, verbose=10):\n",
    "    \"\"\"\n",
    "    Launch all (λ, α, m0, n0) runs in parallel and log failures & low-R² cases.\n",
    "    \"\"\"\n",
    "    if model_kwargs is None:\n",
    "        model_kwargs = {}\n",
    "\n",
    "    tasks = [(lam, alpha, m0, n0)\n",
    "             for lam in lambda_vals\n",
    "             for alpha in alpha_vals\n",
    "             for m0 in m0_vals\n",
    "             for n0 in n0_vals]\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=verbose, backend=\"loky\")(\n",
    "        delayed(run_one)(\n",
    "            lam, alpha, m0, n0,\n",
    "            base_dir=base_dir,\n",
    "            model_kwargs=model_kwargs,\n",
    "            overwrite=overwrite,\n",
    "            snapshot_stride=snapshot_stride\n",
    "        ) for lam, alpha, m0, n0 in tasks\n",
    "    )\n",
    "\n",
    "    done, skipped, failed, low_r2 = [], [], [], []\n",
    "    for r in results:\n",
    "        tag = r[0]\n",
    "        if tag == \"done\":\n",
    "            _, lam, alpha_eff, m0_eff, n0_eff, c, r2 = r\n",
    "            done.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"n0\": n0_eff, \"c\": c, \"r2\": r2})\n",
    "            if (r2 is None) or (isinstance(r2, float) and (np.isnan(r2) or r2 < .999)):\n",
    "                low_r2.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"n0\": n0_eff, \"c\": c, \"r2\": r2})\n",
    "        elif tag == \"skipped\":\n",
    "            _, lam, alpha_eff, m0_eff, n0_eff = r\n",
    "            skipped.append({\"lambda\": lam, \"alpha\": alpha_eff, \"m0\": m0_eff, \"n0\": n0_eff})\n",
    "        elif tag == \"failed\":\n",
    "            _, lam, alpha_orig, m0_orig, n0_orig, msg = r\n",
    "            failed.append({\"lambda\": lam, \"alpha\": alpha_orig, \"m0\": m0_orig, \"n0\": n0_orig, \"error\": msg})\n",
    "\n",
    "    base = Path(base_dir)\n",
    "    _ensure_dir(base)\n",
    "    _atomic_write_json(base / \"failed_runs.json\", failed)\n",
    "    _atomic_write_json(base / \"low_r2_runs.json\", low_r2)\n",
    "\n",
    "    print(f\"✅ Done: {len(done)}, Skipped: {len(skipped)}, Failed: {len(failed)}, Low-R²: {len(low_r2)}\")\n",
    "    if failed:\n",
    "        print(\"❌ Failed runs (sample):\")\n",
    "        for item in failed[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']}, n0={item['n0']} | error: {item['error']}\")\n",
    "    if low_r2:\n",
    "        print(\"⚠️  Low-R² runs (R² < 0.999):\")\n",
    "        for item in low_r2[:20]:\n",
    "            print(f\"  λ={item['lambda']}, α={item['alpha']}, m0={item['m0']}, n0={item['n0']} | c={item['c']} | r2={item['r2']}\")\n",
    "\n",
    "    return {\"done\": done, \"skipped\": skipped, \"failed\": failed, \"low_r2\": low_r2}\n",
    "\n",
    "# -------------------------\n",
    "# Example usage in the notebook\n",
    "# -------------------------\n",
    "# 1) Make sure you've already done:\n",
    "#    from func import Dissertation_Func_1D\n",
    "#\n",
    "# 2) Define your grids and shared kwargs:\n",
    "\n",
    "lambda_vals = [0.001, 0.01, 0.1,  1,10, 100, 100000, 1000000, 100000000]\n",
    "alpha_vals  = [0.001, 0.01, 0.1,  1,  10, 100, 100000, 1000000, 100000000]\n",
    "m0_vals     = [0.1, 0.5, 0.9]\n",
    "n0_vals     = [0.1, 0.3, 0.5, 0.7, 0.9]   # <-- NEW\n",
    "\n",
    "shared_kwargs = dict(\n",
    "    # Your requested defaults\n",
    "    L=200, N=20001, T=400, dt=0.1,\n",
    "    init_type=\"tanh\", steepness=0.85, perc=0.4,\n",
    "    t_start=100, t_end=350, num_points=250,\n",
    "    n0=1.0,   # will be overridden per-run by run_one(...)\n",
    "    K=1.0, rho=1.0, D=1.0, Mmax=1.0\n",
    ")\n",
    "\n",
    "# 3) Run the grid (tweak n_jobs as your machine allows)\n",
    "results = run_grid(lambda_vals, alpha_vals, m0_vals, n0_vals,\n",
    "                   base_dir=\"speeds_func_u0_mini\",\n",
    "                   model_kwargs=shared_kwargs,\n",
    "                   snapshot_stride=150,   # <- only every 150th snapshot (plus last)\n",
    "                   overwrite=False, n_jobs=-2, verbose=10)\n",
    "\n",
    "# 4) (Optional) Quick flagged summary (after results) — example:\n",
    "print(\"\\n=== Summary of Problematic Runs ===\")\n",
    "for item in results[\"failed\"]:\n",
    "    print(f\"FAIL -> λ={item['lambda']}, α={item['alpha']}, m0={item['m0']}, n0={item['n0']} | {item['error']}\")\n",
    "for item in results[\"low_r2\"][:20]:\n",
    "    print(f\"LOW R² -> λ={item['lambda']}, α={item['alpha']}, m0={item['m0']}, n0={item['n0']} | r2={item['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
